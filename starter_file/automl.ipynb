{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os \n",
        "import csv \n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import pkg_resources\n",
        "from matplotlib import pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice, AciWebservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.44.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1667792424102
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "The dataset I will be using for this project is the Top Hits Spotify from 2000-2019 dataset taken from kaggle. The goal of this project will be to predict song popularity given the available features. Popularity is measured on a continuous scale, thus this will be a **regression** problem. \n",
        "\n",
        "\n",
        "The code below will download the dataset from my github repository and create a data asset. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'udacity-capstone'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1667792429412
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "found = False\n",
        "key = \"spotify-songs-dataset\"\n",
        "description_text = \"Top Hits Spotify from 2000-2019\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        data = 'https://raw.githubusercontent.com/ash-mohan/azureMLCapstone/main/starter_file/data/songs_normalize.csv'\n",
        "        dataset = Dataset.Tabular.from_delimited_files(data)        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "         duration_ms        year   popularity  danceability       energy  \\\ncount    2000.000000  2000.00000  2000.000000   2000.000000  2000.000000   \nmean   228748.124500  2009.49400    59.872500      0.667437     0.720366   \nstd     39136.569008     5.85996    21.335577      0.140416     0.152745   \nmin    113000.000000  1998.00000     0.000000      0.129000     0.054900   \n25%    203580.000000  2004.00000    56.000000      0.581000     0.622000   \n50%    223279.500000  2010.00000    65.500000      0.676000     0.736000   \n75%    248133.000000  2015.00000    73.000000      0.764000     0.839000   \nmax    484146.000000  2020.00000    89.000000      0.975000     0.999000   \n\n               key     loudness         mode  speechiness  acousticness  \\\ncount  2000.000000  2000.000000  2000.000000  2000.000000   2000.000000   \nmean      5.378000    -5.512435     0.553500     0.103568      0.128955   \nstd       3.615059     1.933482     0.497254     0.096159      0.173346   \nmin       0.000000   -20.514000     0.000000     0.023200      0.000019   \n25%       2.000000    -6.490250     0.000000     0.039600      0.014000   \n50%       6.000000    -5.285000     1.000000     0.059850      0.055700   \n75%       8.000000    -4.167750     1.000000     0.129000      0.176250   \nmax      11.000000    -0.276000     1.000000     0.576000      0.976000   \n\n       instrumentalness     liveness      valence        tempo  \ncount       2000.000000  2000.000000  2000.000000  2000.000000  \nmean           0.015226     0.181216     0.551690   120.122558  \nstd            0.087771     0.140669     0.220864    26.967112  \nmin            0.000000     0.021500     0.038100    60.019000  \n25%            0.000000     0.088100     0.386750    98.985750  \n50%            0.000000     0.124000     0.557500   120.021500  \n75%            0.000068     0.241000     0.730000   134.265500  \nmax            0.985000     0.853000     0.973000   210.851000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>year</th>\n      <th>popularity</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.00000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>228748.124500</td>\n      <td>2009.49400</td>\n      <td>59.872500</td>\n      <td>0.667437</td>\n      <td>0.720366</td>\n      <td>5.378000</td>\n      <td>-5.512435</td>\n      <td>0.553500</td>\n      <td>0.103568</td>\n      <td>0.128955</td>\n      <td>0.015226</td>\n      <td>0.181216</td>\n      <td>0.551690</td>\n      <td>120.122558</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>39136.569008</td>\n      <td>5.85996</td>\n      <td>21.335577</td>\n      <td>0.140416</td>\n      <td>0.152745</td>\n      <td>3.615059</td>\n      <td>1.933482</td>\n      <td>0.497254</td>\n      <td>0.096159</td>\n      <td>0.173346</td>\n      <td>0.087771</td>\n      <td>0.140669</td>\n      <td>0.220864</td>\n      <td>26.967112</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>113000.000000</td>\n      <td>1998.00000</td>\n      <td>0.000000</td>\n      <td>0.129000</td>\n      <td>0.054900</td>\n      <td>0.000000</td>\n      <td>-20.514000</td>\n      <td>0.000000</td>\n      <td>0.023200</td>\n      <td>0.000019</td>\n      <td>0.000000</td>\n      <td>0.021500</td>\n      <td>0.038100</td>\n      <td>60.019000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>203580.000000</td>\n      <td>2004.00000</td>\n      <td>56.000000</td>\n      <td>0.581000</td>\n      <td>0.622000</td>\n      <td>2.000000</td>\n      <td>-6.490250</td>\n      <td>0.000000</td>\n      <td>0.039600</td>\n      <td>0.014000</td>\n      <td>0.000000</td>\n      <td>0.088100</td>\n      <td>0.386750</td>\n      <td>98.985750</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>223279.500000</td>\n      <td>2010.00000</td>\n      <td>65.500000</td>\n      <td>0.676000</td>\n      <td>0.736000</td>\n      <td>6.000000</td>\n      <td>-5.285000</td>\n      <td>1.000000</td>\n      <td>0.059850</td>\n      <td>0.055700</td>\n      <td>0.000000</td>\n      <td>0.124000</td>\n      <td>0.557500</td>\n      <td>120.021500</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>248133.000000</td>\n      <td>2015.00000</td>\n      <td>73.000000</td>\n      <td>0.764000</td>\n      <td>0.839000</td>\n      <td>8.000000</td>\n      <td>-4.167750</td>\n      <td>1.000000</td>\n      <td>0.129000</td>\n      <td>0.176250</td>\n      <td>0.000068</td>\n      <td>0.241000</td>\n      <td>0.730000</td>\n      <td>134.265500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>484146.000000</td>\n      <td>2020.00000</td>\n      <td>89.000000</td>\n      <td>0.975000</td>\n      <td>0.999000</td>\n      <td>11.000000</td>\n      <td>-0.276000</td>\n      <td>1.000000</td>\n      <td>0.576000</td>\n      <td>0.976000</td>\n      <td>0.985000</td>\n      <td>0.853000</td>\n      <td>0.973000</td>\n      <td>210.851000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667792653826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "\n",
        "print(f\"\\n\\nRows: {df.shape[0]} \\nColumns: {df.shape[1]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 18 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   artist            2000 non-null   object \n 1   song              2000 non-null   object \n 2   duration_ms       2000 non-null   int64  \n 3   explicit          2000 non-null   bool   \n 4   year              2000 non-null   int64  \n 5   popularity        2000 non-null   int64  \n 6   danceability      2000 non-null   float64\n 7   energy            2000 non-null   float64\n 8   key               2000 non-null   int64  \n 9   loudness          2000 non-null   float64\n 10  mode              2000 non-null   int64  \n 11  speechiness       2000 non-null   float64\n 12  acousticness      2000 non-null   float64\n 13  instrumentalness  2000 non-null   float64\n 14  liveness          2000 non-null   float64\n 15  valence           2000 non-null   float64\n 16  tempo             2000 non-null   float64\n 17  genre             2000 non-null   object \ndtypes: bool(1), float64(9), int64(5), object(3)\nmemory usage: 267.7+ KB\n\n\nRows: 2000 \nColumns: 18\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667699101507
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are no missing values , so we will not have to drop nulls. However, this data is meant to be from 2000-2019 and we can see from the output above there are some outliers outside of this range. We will drop these rows along with any duplicate rows. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df[df['year'].between(2000, 2019)].drop_duplicates()\n",
        "new_df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "         duration_ms         year   popularity  danceability       energy  \\\ncount    1899.000000  1899.000000  1899.000000   1899.000000  1899.000000   \nmean   228123.525540  2009.720379    59.558715      0.667637     0.721256   \nstd     39116.687604     5.725938    21.683909      0.140547     0.152511   \nmin    113000.000000  2000.000000     0.000000      0.129000     0.054900   \n25%    203273.000000  2005.000000    56.000000      0.581000     0.624500   \n50%    222920.000000  2010.000000    65.000000      0.676000     0.738000   \n75%    247086.000000  2015.000000    73.000000      0.765000     0.839000   \nmax    484146.000000  2019.000000    89.000000      0.975000     0.999000   \n\n               key     loudness         mode  speechiness  acousticness  \\\ncount  1899.000000  1899.000000  1899.000000  1899.000000   1899.000000   \nmean      5.379147    -5.503538     0.553976     0.104413      0.127722   \nstd       3.610882     1.931067     0.497209     0.096523      0.172951   \nmin       0.000000   -20.514000     0.000000     0.023200      0.000019   \n25%       2.000000    -6.480000     0.000000     0.039900      0.013550   \n50%       6.000000    -5.279000     1.000000     0.061300      0.055300   \n75%       8.000000    -4.167000     1.000000     0.130500      0.175000   \nmax      11.000000    -0.276000     1.000000     0.576000      0.976000   \n\n       instrumentalness     liveness      valence        tempo  \ncount       1899.000000  1899.000000  1899.000000  1899.000000  \nmean           0.015525     0.181934     0.552579   120.115425  \nstd            0.089036     0.140827     0.220361    26.986107  \nmin            0.000000     0.021500     0.038100    60.019000  \n25%            0.000000     0.088750     0.389500    98.605000  \n50%            0.000000     0.125000     0.559000   120.028000  \n75%            0.000064     0.242000     0.730500   134.124500  \nmax            0.985000     0.853000     0.973000   210.851000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>year</th>\n      <th>popularity</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n      <td>1899.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>228123.525540</td>\n      <td>2009.720379</td>\n      <td>59.558715</td>\n      <td>0.667637</td>\n      <td>0.721256</td>\n      <td>5.379147</td>\n      <td>-5.503538</td>\n      <td>0.553976</td>\n      <td>0.104413</td>\n      <td>0.127722</td>\n      <td>0.015525</td>\n      <td>0.181934</td>\n      <td>0.552579</td>\n      <td>120.115425</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>39116.687604</td>\n      <td>5.725938</td>\n      <td>21.683909</td>\n      <td>0.140547</td>\n      <td>0.152511</td>\n      <td>3.610882</td>\n      <td>1.931067</td>\n      <td>0.497209</td>\n      <td>0.096523</td>\n      <td>0.172951</td>\n      <td>0.089036</td>\n      <td>0.140827</td>\n      <td>0.220361</td>\n      <td>26.986107</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>113000.000000</td>\n      <td>2000.000000</td>\n      <td>0.000000</td>\n      <td>0.129000</td>\n      <td>0.054900</td>\n      <td>0.000000</td>\n      <td>-20.514000</td>\n      <td>0.000000</td>\n      <td>0.023200</td>\n      <td>0.000019</td>\n      <td>0.000000</td>\n      <td>0.021500</td>\n      <td>0.038100</td>\n      <td>60.019000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>203273.000000</td>\n      <td>2005.000000</td>\n      <td>56.000000</td>\n      <td>0.581000</td>\n      <td>0.624500</td>\n      <td>2.000000</td>\n      <td>-6.480000</td>\n      <td>0.000000</td>\n      <td>0.039900</td>\n      <td>0.013550</td>\n      <td>0.000000</td>\n      <td>0.088750</td>\n      <td>0.389500</td>\n      <td>98.605000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>222920.000000</td>\n      <td>2010.000000</td>\n      <td>65.000000</td>\n      <td>0.676000</td>\n      <td>0.738000</td>\n      <td>6.000000</td>\n      <td>-5.279000</td>\n      <td>1.000000</td>\n      <td>0.061300</td>\n      <td>0.055300</td>\n      <td>0.000000</td>\n      <td>0.125000</td>\n      <td>0.559000</td>\n      <td>120.028000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>247086.000000</td>\n      <td>2015.000000</td>\n      <td>73.000000</td>\n      <td>0.765000</td>\n      <td>0.839000</td>\n      <td>8.000000</td>\n      <td>-4.167000</td>\n      <td>1.000000</td>\n      <td>0.130500</td>\n      <td>0.175000</td>\n      <td>0.000064</td>\n      <td>0.242000</td>\n      <td>0.730500</td>\n      <td>134.124500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>484146.000000</td>\n      <td>2019.000000</td>\n      <td>89.000000</td>\n      <td>0.975000</td>\n      <td>0.999000</td>\n      <td>11.000000</td>\n      <td>-0.276000</td>\n      <td>1.000000</td>\n      <td>0.576000</td>\n      <td>0.976000</td>\n      <td>0.985000</td>\n      <td>0.853000</td>\n      <td>0.973000</td>\n      <td>210.851000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667706810733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rows: {new_df.shape[0]} \\nColumns: {new_df.shape[1]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Rows: 1899 \nColumns: 18\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667699284532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only 2000 data points so test size will be small \n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Training Data: {train_data.shape[0]} entries\")\n",
        "print(f\"Testing Data: {test_data.shape[0]} entries\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training Data: 1800 entries\nTesting Data: 200 entries\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667792668000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save csv file and upload to datastore\n",
        "pd.DataFrame(train_data).to_csv(\"data/train_dataset.csv\", index=False)\n",
        "pd.DataFrame(test_data).to_csv(\"data/test_dataset.csv\", index=False)\n",
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload(src_dir='./data', target_path='spotify_exp', overwrite=True, show_progress=True)\n",
        "\n",
        "training_data = TabularDatasetFactory.from_delimited_files(path=datastore.path('spotify_exp/train_dataset.csv'))\n",
        "testing_data = TabularDatasetFactory.from_delimited_files(path=datastore.path('spotify_exp/test_dataset.csv'))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 5 files\nUploading ./data/.amlignore\nUploaded ./data/.amlignore, 1 files out of an estimated total of 5\nUploading ./data/.amlignore.amltmp\nUploaded ./data/.amlignore.amltmp, 2 files out of an estimated total of 5\nUploading ./data/songs_normalize.csv\nUploaded ./data/songs_normalize.csv, 3 files out of an estimated total of 5\nUploading ./data/test_dataset.csv\nUploaded ./data/test_dataset.csv, 4 files out of an estimated total of 5\nUploading ./data/train_dataset.csv\nUploaded ./data/train_dataset.csv, 5 files out of an estimated total of 5\nUploaded 5 files\nUploading an estimated of 5 files\nUploading ./data/.amlignore\nUploaded ./data/.amlignore, 1 files out of an estimated total of 5\nUploading ./data/.amlignore.amltmp\nUploaded ./data/.amlignore.amltmp, 2 files out of an estimated total of 5\nUploading ./data/songs_normalize.csv\nUploaded ./data/songs_normalize.csv, 3 files out of an estimated total of 5\nUploading ./data/test_dataset.csv\nUploaded ./data/test_dataset.csv, 4 files out of an estimated total of 5\nUploading ./data/train_dataset.csv\nUploaded ./data/train_dataset.csv, 5 files out of an estimated total of 5\nUploaded 5 files\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667792678144
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "In order to ensure a reasonable training time, I set experiment timeout to 15 minutes. The dataset I am using is relatively small, so longer training times may not give better results. Additonally, I set the maximum current iterations to 5 to take advantage of the hardware and stay within the 15 minute bound.  Early stopping is also enabled to make the training process much more efficient. Given the small size of my dataset, I chose a larger value for cross validations to ensure the best possible results. Featurization is set to auto to take advantage of auto ML capabilities. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl.utilities import get_primary_metrics\n",
        "\n",
        "get_primary_metrics(\"regression\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "['spearman_correlation',\n 'normalized_root_mean_squared_error',\n 'normalized_mean_absolute_error',\n 'r2_score']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667793783403
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "amlcompute_cluster_name = \"auto-ml\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress.\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded....................................\nAmlCompute wait for completion finished\n\nWait timeout has been reached\nCurrent provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667793988799
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"n_cross_validations\": 5,\n",
        "    \"experiment_timeout_hours\": .25,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'normalized_root_mean_squared_error'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"regression\",\n",
        "                             training_data=training_data,\n",
        "                             label_column_name=\"popularity\",\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1667794122241
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-capstone</td><td>AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658?wsid=/subscriptions/6b66a03f-9834-4d5b-92f6-b82e733674dc/resourcegroups/azuremleast/workspaces/capstonedeploy&amp;tid=a1ab4d21-4797-4645-90e8-98fbc87b1b92\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1667794134073
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(remote_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c264c60ab5e54d2abc51cf199e7c53dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658?wsid=/subscriptions/6b66a03f-9834-4d5b-92f6-b82e733674dc/resourcegroups/azuremleast/workspaces/capstonedeploy&tid=a1ab4d21-4797-4645-90e8-98fbc87b1b92\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"run_properties\": {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"created_utc\": \"2022-11-07T04:08:52.868061Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"normalized_root_mean_squared_error\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"5\", \"target\": \"auto-ml\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"udacity-capstone\\\",\\\"subscription_id\\\":\\\"6b66a03f-9834-4d5b-92f6-b82e733674dc\\\",\\\"resource_group\\\":\\\"azuremleast\\\",\\\"workspace_name\\\":\\\"capstonedeploy\\\",\\\"region\\\":\\\"eastus2\\\",\\\"compute_target\\\":\\\"auto-ml\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"remote\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"enable_batch_run\\\":true,\\\"enable_run_restructure\\\":false,\\\"start_auxiliary_runs_before_parent_complete\\\":false,\\\"enable_code_generation\\\":true,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"normalized_root_mean_squared_error\\\",\\\"task_type\\\":\\\"regression\\\",\\\"positive_label\\\":null,\\\"data_script\\\":null,\\\"test_size\\\":0.0,\\\"test_include_predictions_only\\\":false,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":5,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":5,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":15,\\\"experiment_exit_score\\\":null,\\\"partition_column_names\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowDNN\\\",\\\"TensorFlowLinearRegressor\\\"],\\\"supported_models\\\":[\\\"SGD\\\",\\\"GradientBoosting\\\",\\\"DecisionTree\\\",\\\"XGBoostRegressor\\\",\\\"TensorFlowDNN\\\",\\\"KNN\\\",\\\"RandomForest\\\",\\\"FastLinearRegressor\\\",\\\"LightGBM\\\",\\\"TensorFlowLinearRegressor\\\",\\\"ElasticNet\\\",\\\"TabnetRegressor\\\",\\\"OnlineGradientDescentRegressor\\\",\\\"ExtremeRandomTrees\\\",\\\"LassoLars\\\"],\\\"private_models\\\":[],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"azureml_automl.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":\\\"STANDARD_DS3_V2\\\",\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"scenario\\\":\\\"AutoML\\\",\\\"environment_label\\\":null,\\\"save_mlflow\\\":false,\\\"enable_categorical_indicators\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"arguments\\\":null,\\\"dataset_id\\\":\\\"8093a43a-937b-4fee-9c36-a7a3c27f2d56\\\",\\\"hyperdrive_config\\\":null,\\\"validation_dataset_id\\\":null,\\\"run_source\\\":null,\\\"metrics\\\":null,\\\"enable_metric_confidence\\\":false,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":true,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"popularity\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"minimize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": \"{\\\\\\\"training_data\\\\\\\": {\\\\\\\"datasetId\\\\\\\": \\\\\\\"8093a43a-937b-4fee-9c36-a7a3c27f2d56\\\\\\\"}, \\\\\\\"datasets\\\\\\\": 0}\", \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"regression\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.44.0\\\", \\\"azureml-training-tabular\\\": \\\"1.44.0\\\", \\\"azureml-train\\\": \\\"1.44.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.44.0\\\", \\\"azureml-train-core\\\": \\\"1.44.0\\\", \\\"azureml-train-automl\\\": \\\"1.44.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.44.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.44.0\\\", \\\"azureml-tensorboard\\\": \\\"1.44.0\\\", \\\"azureml-telemetry\\\": \\\"1.44.0\\\", \\\"azureml-sdk\\\": \\\"1.44.0\\\", \\\"azureml-samples\\\": \\\"0+unknown\\\", \\\"azureml-responsibleai\\\": \\\"1.44.0\\\", \\\"azureml-pipeline\\\": \\\"1.44.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.44.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.44.0\\\", \\\"azureml-opendatasets\\\": \\\"1.44.0\\\", \\\"azureml-mlflow\\\": \\\"1.44.0\\\", \\\"azureml-interpret\\\": \\\"1.44.0\\\", \\\"azureml-inference-server-http\\\": \\\"0.7.4\\\", \\\"azureml-explain-model\\\": \\\"1.44.0\\\", \\\"azureml-defaults\\\": \\\"1.44.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.44.0\\\", \\\"azureml-dataprep\\\": \\\"4.2.2\\\", \\\"azureml-dataprep-rslex\\\": \\\"2.8.1\\\", \\\"azureml-dataprep-native\\\": \\\"38.0.0\\\", \\\"azureml-datadrift\\\": \\\"1.44.0\\\", \\\"azureml-core\\\": \\\"1.44.0\\\", \\\"azureml-contrib-services\\\": \\\"1.44.0\\\", \\\"azureml-contrib-server\\\": \\\"1.44.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.44.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.44.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.44.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.44.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.44.0\\\", \\\"azureml-contrib-automl-pipeline-steps\\\": \\\"1.44.0\\\", \\\"azureml-cli-common\\\": \\\"1.44.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.44.0\\\", \\\"azureml-automl-dnn-nlp\\\": \\\"1.44.0\\\", \\\"azureml-automl-core\\\": \\\"1.44.0\\\", \\\"azureml-accel-models\\\": \\\"1.44.0\\\"}\", \"_aml_system_scenario_identification\": \"Remote.Parent\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_label\": \"prod\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_label\": \"prod\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"CancelUri\": \"https://eastus2.api.azureml.ms/jasmine/v1.0/subscriptions/6b66a03f-9834-4d5b-92f6-b82e733674dc/resourceGroups/azuremleast/providers/Microsoft.MachineLearningServices/workspaces/capstonedeploy/experimentids/3c6173ae-eb28-4399-9782-90d710b361a2/cancel/AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"ClientSdkVersion\": \"1.46.1\", \"snapshotId\": \"00000000-0000-0000-0000-000000000000\", \"SetupRunId\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_setup\", \"SetupRunContainerId\": \"dcid.AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_setup\", \"FeaturizationRunJsonPath\": \"featurizer_container.json\", \"FeaturizationRunId\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_featurize\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": false, \\\"has_extra_col\\\": true, \\\"dataset_classes\\\": 74, \\\"dataset_features\\\": 9588, \\\"dataset_samples\\\": 1800, \\\"single_frequency_class_detected\\\": false}\", \"ModelExplainRunId\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_ModelExplain\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_automl_run_workspace_id\": \"2d654948-33da-454d-bb1f-c6e099f464de\", \"_aml_system_azureml.automlComponent\": \"AutoML\", \"pipeline_id\": \"\", \"score\": \"\", \"predicted_cost\": \"\", \"fit_time\": \"\", \"training_percent\": \"\", \"iteration\": \"\", \"run_preprocessor\": \"\", \"run_algorithm\": \"\", \"_aml_system_azureml.automl_early_exit_message\": \"Experiment timeout reached, hence experiment stopped. Current experiment timeout: 0 hour(s) 15 minute(s)\", \"automl_best_child_run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_21\", \"model_explain_best_run_child_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_21\"}, \"end_time_utc\": \"2022-11-07T04:34:10.619857Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:25:17\", \"run_number\": \"1667794132\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_setup\", \"run_number\": 1667794145, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-11-07T04:11:35.605921Z\", \"end_time\": \"2022-11-07T04:12:40.032146Z\", \"created_time\": \"2022-11-07T04:09:05.693116Z\", \"created_time_dt\": \"2022-11-07T04:09:05.693116Z\", \"duration\": \"0:03:34\", \"iteration\": null, \"goal\": null, \"run_name\": \"Completed\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_featurize\", \"run_number\": 1667794360, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"automl.featurization\", \"training_percent\": null, \"start_time\": \"2022-11-07T04:12:40.669582Z\", \"end_time\": \"2022-11-07T04:14:34.803506Z\", \"created_time\": \"2022-11-07T04:12:40.342586Z\", \"created_time_dt\": \"2022-11-07T04:12:40.342586Z\", \"duration\": \"0:01:54\", \"iteration\": null, \"goal\": null, \"run_name\": \"Completed\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_0\", \"run_number\": 1667794476, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:52.29604Z\", \"end_time\": \"2022-11-07T04:15:05.111063Z\", \"created_time\": \"2022-11-07T04:14:36.240524Z\", \"created_time_dt\": \"2022-11-07T04:14:36.240524Z\", \"duration\": \"0:00:28\", \"iteration\": \"0\", \"goal\": \"normalized_root_mean_squared_error_min\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.24855108, \"best_metric\": 0.24855108}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_worker_0\", \"run_number\": 1667794477, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-11-07T04:14:44.363426Z\", \"end_time\": \"2022-11-07T04:21:17.378338Z\", \"created_time\": \"2022-11-07T04:14:37.978576Z\", \"created_time_dt\": \"2022-11-07T04:14:37.978576Z\", \"duration\": \"0:06:39\", \"iteration\": null, \"goal\": null, \"run_name\": \"Completed\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_4\", \"run_number\": 1667794478, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:21:34.325527Z\", \"end_time\": \"2022-11-07T04:24:20.411628Z\", \"created_time\": \"2022-11-07T04:14:38.128396Z\", \"created_time_dt\": \"2022-11-07T04:14:38.128396Z\", \"duration\": \"0:09:42\", \"iteration\": \"4\", \"goal\": \"normalized_root_mean_squared_error_min\", \"run_name\": \"MaxAbsScaler, ElasticNet\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.27377492, \"best_metric\": 0.24855108}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_worker_1\", \"run_number\": 1667794479, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-11-07T04:21:26.288586Z\", \"end_time\": \"2022-11-07T04:29:20.798573Z\", \"created_time\": \"2022-11-07T04:14:39.593739Z\", \"created_time_dt\": \"2022-11-07T04:14:39.593739Z\", \"duration\": \"0:14:41\", \"iteration\": null, \"goal\": null, \"run_name\": \"Completed\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_10\", \"run_number\": 1667794480, \"metric\": null, \"status\": \"Canceled\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:40.793675Z\", \"end_time\": \"2022-11-07T04:32:40.869787Z\", \"created_time\": \"2022-11-07T04:14:40.793675Z\", \"created_time_dt\": \"2022-11-07T04:14:40.793675Z\", \"duration\": \"0:18:00\", \"iteration\": \"10\", \"goal\": null, \"run_name\": \"Canceled\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_11\", \"run_number\": 1667794481, \"metric\": null, \"status\": \"Canceled\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:41.223545Z\", \"end_time\": \"2022-11-07T04:32:41.045804Z\", \"created_time\": \"2022-11-07T04:14:41.223545Z\", \"created_time_dt\": \"2022-11-07T04:14:41.223545Z\", \"duration\": \"0:17:59\", \"iteration\": \"11\", \"goal\": null, \"run_name\": \"Canceled\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_13\", \"run_number\": 1667794482, \"metric\": null, \"status\": \"Canceled\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:42.047913Z\", \"end_time\": \"2022-11-07T04:32:41.134479Z\", \"created_time\": \"2022-11-07T04:14:42.047913Z\", \"created_time_dt\": \"2022-11-07T04:14:42.047913Z\", \"duration\": \"0:17:59\", \"iteration\": \"13\", \"goal\": null, \"run_name\": \"Canceled\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_16\", \"run_number\": 1667794483, \"metric\": null, \"status\": \"Canceled\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:43.247821Z\", \"end_time\": \"2022-11-07T04:32:41.00765Z\", \"created_time\": \"2022-11-07T04:14:43.247821Z\", \"created_time_dt\": \"2022-11-07T04:14:43.247821Z\", \"duration\": \"0:17:57\", \"iteration\": \"16\", \"goal\": null, \"run_name\": \"Canceled\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_18\", \"run_number\": 1667794484, \"metric\": null, \"status\": \"Canceled\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:14:44.009384Z\", \"end_time\": \"2022-11-07T04:32:40.908298Z\", \"created_time\": \"2022-11-07T04:14:44.009384Z\", \"created_time_dt\": \"2022-11-07T04:14:44.009384Z\", \"duration\": \"0:17:56\", \"iteration\": \"18\", \"goal\": null, \"run_name\": \"Canceled\", \"run_properties\": null}, {\"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_20\", \"run_number\": 1667795562, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": \"100\", \"start_time\": \"2022-11-07T04:32:51.32573Z\", \"end_time\": \"2022-11-07T04:33:26.818358Z\", \"created_time\": \"2022-11-07T04:32:42.254781Z\", \"created_time_dt\": \"2022-11-07T04:32:42.254781Z\", \"duration\": \"0:00:44\", \"iteration\": \"20\", \"goal\": \"normalized_root_mean_squared_error_min\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"estimators=[('6', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True\", \"primary_metric\": 0.24049851, \"best_metric\": 0.24049851}], \"children_metrics\": {\"categories\": [0], \"series\": {\"r2_score\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"r2_score\", \"stepped\": false, \"type\": \"scatter\", \"data\": [-0.07709763544134826, -0.31139712399182257, -0.008735022032192008]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"r2_score_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [-0.07709763544134826, -0.07709763544134826, -0.008735022032192008]}], \"spearman_correlation\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"spearman_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.2425509814290195, 0.18813722095174218, 0.28686415575533575]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"spearman_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.2425509814290195, 0.2425509814290195, 0.28686415575533575]}], \"root_mean_squared_log_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"root_mean_squared_log_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [1.1570415951573136, 1.2396172859710917, 1.1577558747293766]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"root_mean_squared_log_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [1.1570415951573136, 1.1570415951573136, 1.1570415951573136]}], \"root_mean_squared_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"root_mean_squared_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [22.121046441615796, 24.36596780789147, 21.404367517479972]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"root_mean_squared_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [22.121046441615796, 22.121046441615796, 21.404367517479972]}], \"normalized_root_mean_squared_log_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"normalized_root_mean_squared_log_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.25713122996875376, 0.2754821596443455, 0.2572899654763404]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"normalized_root_mean_squared_log_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.25713122996875376, 0.25713122996875376, 0.25713122996875376]}], \"explained_variance\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"explained_variance\", \"stepped\": false, \"type\": \"scatter\", \"data\": [-0.07524710334212022, -0.3017746976097263, -0.005255467614242737]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"explained_variance_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [-0.07524710334212022, -0.07524710334212022, -0.005255467614242737]}], \"median_absolute_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"median_absolute_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [9.307292076685789, 11.537067184005569, 8.738120079181929]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"median_absolute_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [9.307292076685789, 9.307292076685789, 8.738120079181929]}], \"normalized_median_absolute_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"normalized_median_absolute_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.10457631546837967, 0.12962996835961313, 0.0981811244851902]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"normalized_median_absolute_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.10457631546837967, 0.10457631546837967, 0.0981811244851902]}], \"mean_absolute_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"mean_absolute_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [15.06228930499942, 17.04226734872052, 14.06219041859363]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"mean_absolute_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [15.06228930499942, 15.06228930499942, 14.06219041859363]}], \"mean_absolute_percentage_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"mean_absolute_percentage_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [127.20904166692897, 130.92426844415678, 127.10942697161701]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"mean_absolute_percentage_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [127.20904166692897, 127.20904166692897, 127.10942697161701]}], \"normalized_mean_absolute_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"normalized_mean_absolute_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.1692392056741508, 0.19148614998562383, 0.1580021395347599]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"normalized_mean_absolute_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.1692392056741508, 0.1692392056741508, 0.1580021395347599]}], \"normalized_root_mean_squared_error\": [{\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"markers\", \"name\": \"normalized_root_mean_squared_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.24855108361366063, 0.27377491918979174, 0.24049851143235923]}, {\"categories\": [\"0\", \"4\", \"20\"], \"mode\": \"lines\", \"name\": \"normalized_root_mean_squared_error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.24855108361366063, 0.24855108361366063, 0.24049851143235923]}]}, \"metricName\": null, \"primaryMetricName\": \"normalized_root_mean_squared_error\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\", \"DatasetFeaturization\", \"DatasetFeaturizationCompleted\", \"DatasetCrossValidationSplit\", \"ModelSelection\", \"BestRunExplainModel\", \"ModelExplanationDataSetSetup\", \"PickSurrogateModel\", \"EngineeredFeatureExplanations\", \"EngineeredFeatureExplanations\", \"RawFeaturesExplanations\", \"RawFeaturesExplanations\", \"BestRunExplainModel\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\", \"Completed fit featurizers and featurizing the dataset.\", \"Generating individually featurized CV splits.\", \"Beginning model selection.\", \"Best run model explanations started\", \"Model explanations data setup completed\", \"Choosing LightGBM as the surrogate model for explanations\", \"Computation of engineered features started\", \"Computation of engineered features completed\", \"Computation of raw features started\", \"Computation of raw features completed\", \"Best run model explanations completed\"]}]}, {\"name\": \"root_mean_squared_log_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [1.164607745074644]}]}, {\"name\": \"root_mean_squared_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [20.804856798704403]}]}, {\"name\": \"r2_score\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.04722929446180728]}]}, {\"name\": \"mean_absolute_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [14.042307773453317]}]}, {\"name\": \"spearman_correlation\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.28289967538530014]}]}, {\"name\": \"normalized_root_mean_squared_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.23376243594049892]}]}, {\"name\": \"median_absolute_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [9.478087923125809]}]}, {\"name\": \"normalized_median_absolute_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.1064953699227619]}]}, {\"name\": \"mean_absolute_percentage_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [131.9234495243956]}]}, {\"name\": \"explained_variance\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.05041451143975908]}]}, {\"name\": \"normalized_mean_absolute_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.15777873902756534]}]}, {\"name\": \"normalized_root_mean_squared_log_error\", \"run_id\": \"AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658\", \"categories\": [0], \"series\": [{\"data\": [0.2588126677342705]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1667794230769
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve best model from Pipeline Run\n",
        "best_run, fitted_model = remote_run.get_output()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:The version of the SDK does not match the version the model was trained on.\nWARNING:root:The consistency in the result may not be guaranteed.\nWARNING:root:Package:azureml-automl-core, training version:1.46.1, current version:1.44.0\nPackage:azureml-automl-runtime, training version:1.46.1, current version:1.44.0\nPackage:azureml-core, training version:1.46.0, current version:1.44.0\nPackage:azureml-dataprep, training version:4.5.7, current version:4.2.2\nPackage:azureml-dataprep-rslex, training version:2.11.4, current version:2.8.1\nPackage:azureml-dataset-runtime, training version:1.46.0, current version:1.44.0\nPackage:azureml-defaults, training version:1.46.0, current version:1.44.0\nPackage:azureml-interpret, training version:1.46.0, current version:1.44.0\nPackage:azureml-mlflow, training version:1.46.0, current version:1.44.0\nPackage:azureml-pipeline-core, training version:1.46.0, current version:1.44.0\nPackage:azureml-responsibleai, training version:1.46.0, current version:1.44.0\nPackage:azureml-telemetry, training version:1.46.0, current version:1.44.0\nPackage:azureml-train-automl-client, training version:1.46.0, current version:1.44.0\nPackage:azureml-train-automl-runtime, training version:1.46.1, current version:1.44.0\nPackage:azureml-train-core, training version:1.46.0, current version:1.44.0\nPackage:azureml-train-restclients-hyperdrive, training version:1.46.0, current version:1.44.0\nPackage:azureml-training-tabular, training version:1.46.1, current version:1.44.0\nWARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1667795946040
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_run)\n",
        "print(best_run.properties[\"score\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: udacity-capstone,\nId: AutoML_b151aac2-26f8-4636-95a9-681b5fdd4658_21,\nType: azureml.scriptrun,\nStatus: Completed)\n0.23376243594049892\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667795946204
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "best_model = remote_run.register_model(model_name='spotify-popularity-model')\n",
        "\n",
        "best_model.download(target_dir=\"outputs\", exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "'outputs/model.pkl'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667796004826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=2,\n",
        "    description=\"Get popularity score for spotify song\",\n",
        ")\n",
        "\n",
        "# save the environment\n",
        "myenv = Environment.get(workspace=ws, name=\"AzureML-AutoML\")\n",
        "myenv.save_to_directory('env', overwrite=True)\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667796012898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use configs and models generated above\n",
        "service=Model.deploy(workspace=ws,\n",
        "                    name=\"modelwebservice\",\n",
        "                    models=[best_model],\n",
        "                    inference_config=inference_config,\n",
        "                    deployment_config=aciconfig)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-11-07 04:40:20+00:00 Creating Container Registry if not exists.\n2022-11-07 04:40:20+00:00 Registering the environment.\n2022-11-07 04:40:21+00:00 Use the existing image.\n2022-11-07 04:40:21+00:00 Submitting deployment to compute.\n2022-11-07 04:40:25+00:00 Checking the status of deployment modelwebservice..\n2022-11-07 04:42:39+00:00 Checking the status of inference endpoint modelwebservice.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667796196619
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if service.state == \"Healthy\":\n",
        "    X_test = test_data.drop(\"popularity\", axis=1)\n",
        "    # Serialize the first row of the test data into json\n",
        "    X_test_json = X_test[:1].to_json(orient=\"records\")\n",
        "    print(f\"Data: {X_test_json}\")\n",
        "    # Call the service to get the predictions and the engineered and raw explanations\n",
        "    output = service.run(X_test_json)\n",
        "    # Print the predicted value\n",
        "    print(f\"\\nPrediction: {output['predictions']}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data: [{\"artist\":\"Charlie Puth\",\"song\":\"How Long\",\"duration_ms\":200853,\"explicit\":false,\"year\":2018,\"danceability\":0.845,\"energy\":0.561,\"key\":1,\"loudness\":-5.253,\"mode\":0,\"speechiness\":0.0778,\"acousticness\":0.211,\"instrumentalness\":0.00000349,\"liveness\":0.0383,\"valence\":0.811,\"tempo\":109.974,\"genre\":\"pop\"}]\n\nPrediction: [65.6844329837312]\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1667796316761
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "test_data = testing_data.to_pandas_dataframe().drop(\"popularity\", axis=1) \n",
        "samples = test_data[:2].to_json(orient=\"records\")\n",
        "samples"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "'[{\"artist\":\"Charlie Puth\",\"song\":\"How Long\",\"duration_ms\":200853,\"explicit\":false,\"year\":2018,\"danceability\":0.845,\"energy\":0.561,\"key\":1,\"loudness\":-5.253,\"mode\":0,\"speechiness\":0.0778,\"acousticness\":0.211,\"instrumentalness\":0.00000349,\"liveness\":0.0383,\"valence\":0.811,\"tempo\":109.974,\"genre\":\"pop\"},{\"artist\":\"50 Cent\",\"song\":\"21 Questions\",\"duration_ms\":224440,\"explicit\":true,\"year\":2003,\"danceability\":0.646,\"energy\":0.813,\"key\":6,\"loudness\":-3.846,\"mode\":0,\"speechiness\":0.299,\"acousticness\":0.349,\"instrumentalness\":0.0000937,\"liveness\":0.0427,\"valence\":0.895,\"tempo\":92.729,\"genre\":\"hip hop, pop\"}]'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667797191647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "# create request \n",
        "headers = {'Content-Type':'application/json'}\n",
        "\n",
        "# uncomment if auth is enabled \n",
        "#headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "\n",
        "response = requests.post(scoring_uri,samples,headers=headers)\n",
        "print(response.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\"predictions\": [65.6844329837312, 63.63655269426005]}\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667797518412
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view service logs \n",
        "service.get_logs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 129,
          "data": {
            "text/plain": "'2022-11-06T07:13:01,090709800+00:00 - rsyslog/run \\n2022-11-06T07:13:01,090879100+00:00 - iot-server/run \\n2022-11-06T07:13:01,097230000+00:00 - gunicorn/run \\n2022-11-06T07:13:01,098685100+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,100536700+00:00 | gunicorn/run | ###############################################\\n2022-11-06T07:13:01,105817800+00:00 | gunicorn/run | AzureML Container Runtime Information\\n2022-11-06T07:13:01,107496400+00:00 | gunicorn/run | ###############################################\\n2022-11-06T07:13:01,108899600+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,114997000+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,127288400+00:00 | gunicorn/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20220930.v4\\n2022-11-06T07:13:01,128595600+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,129896700+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,134600200+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n2022-11-06T07:13:01,139964000+00:00 | gunicorn/run | PYTHONPATH environment variable: \\n2022-11-06T07:13:01,143866200+00:00 | gunicorn/run | \\n2022-11-06T07:13:01,146992800+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\n\\n2022-11-06T07:13:01,147644300+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-11-06T07:13:01,517095900+00:00 - iot-server/finish 1 0\\n2022-11-06T07:13:01,520456200+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nadal==1.2.7\\napplicationinsights==0.11.10\\nargcomplete==2.0.0\\narviz @ file:///tmp/build/80754af9/arviz_1614019183254/work\\nattrs==22.1.0\\nazure-common==1.1.28\\nazure-core==1.26.0\\nazure-graphrbac==0.61.1\\nazure-identity==1.11.0\\nazure-mgmt-authorization==2.0.0\\nazure-mgmt-containerregistry==10.0.0\\nazure-mgmt-core==1.3.2\\nazure-mgmt-keyvault==10.1.0\\nazure-mgmt-resource==21.2.1\\nazure-mgmt-storage==20.1.0\\nazure-storage-blob==12.13.0\\nazure-storage-queue==12.5.0\\nazureml-automl-core==1.47.0\\nazureml-automl-runtime==1.47.0\\nazureml-core==1.47.0\\nazureml-dataprep==4.5.7\\nazureml-dataprep-native==38.0.0\\nazureml-dataprep-rslex==2.11.4\\nazureml-dataset-runtime==1.47.0\\nazureml-defaults==1.47.0\\nazureml-inference-server-http==0.7.6\\nazureml-interpret==1.47.0\\nazureml-mlflow==1.47.0\\nazureml-pipeline-core==1.47.0\\nazureml-responsibleai==1.47.0\\nazureml-telemetry==1.47.0\\nazureml-train-automl-client==1.47.0\\nazureml-train-automl-runtime==1.47.0\\nazureml-train-core==1.47.0\\nazureml-train-restclients-hyperdrive==1.47.0\\nazureml-training-tabular==1.47.0\\nbackcall==0.2.0\\nbackports.tempfile==1.0\\nbackports.weakref==1.0.post1\\nbcrypt==4.0.1\\nbokeh==2.4.3\\nboto==2.49.0\\nboto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1602889982367/work\\nbotocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1602884371056/work\\nbrotlipy==0.7.0\\ncachetools==5.2.0\\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\\ncffi @ file:///tmp/abs_98z5h56wf8/croots/recipe/cffi_1659598650955/work\\ncftime @ file:///tmp/build/80754af9/cftime_1638345281172/work\\ncharset-normalizer==2.1.1\\nclick @ file:///home/linux1/recipes/ci/click_1610990599742/work\\ncloudpickle @ file:///Users/ktietz/demo/mc3/conda-bld/cloudpickle_1629142150447/work\\nconfigparser==3.7.4\\ncontextlib2==21.6.0\\nconvertdate @ file:///tmp/build/80754af9/convertdate_1634070773133/work\\ncryptography @ file:///tmp/build/80754af9/cryptography_1652083456434/work\\ncycler @ file:///tmp/build/80754af9/cycler_1637851556182/work\\nCython==0.29.17\\ndask==2.30.0\\ndatabricks-cli==0.17.3\\ndataclasses==0.6\\ndebugpy==1.6.3\\ndecorator==5.1.1\\ndice-ml==0.8\\ndill==0.3.6\\ndistributed==2.30.1\\ndistro==1.8.0\\ndocker==6.0.0\\ndotnetcore2==3.1.23\\ndowhy==0.7.1\\neconml==0.13.1\\nentrypoints==0.4\\nephem @ file:///tmp/build/80754af9/ephem_1638960312619/work\\nerroranalysis==0.3.12\\nfairlearn==0.7.0\\nfbprophet @ file:///home/conda/feedstock_root/build_artifacts/fbprophet_1599365534439/work\\nfire==0.4.0\\nFlask==2.1.3\\nFlask-Cors==3.0.10\\nflatbuffers==22.10.26\\nfonttools==4.25.0\\nfsspec==2022.10.0\\ngensim==3.8.3\\ngitdb==4.0.9\\nGitPython==3.1.29\\ngoogle-api-core==2.10.2\\ngoogle-auth==2.13.0\\ngoogleapis-common-protos==1.56.4\\ngunicorn==20.1.0\\nh5py==3.7.0\\nHeapDict==1.0.1\\nholidays @ file:///home/conda/feedstock_root/build_artifacts/holidays_1595448845196/work\\nhumanfriendly==10.0\\nidna @ file:///tmp/build/80754af9/idna_1637925883363/work\\nimportlib-metadata==5.0.0\\nimportlib-resources==5.10.0\\ninference-schema==1.5\\ninterpret-community==0.27.0\\ninterpret-core==0.2.7\\nipykernel==6.6.0\\nipython==7.34.0\\nisodate==0.6.1\\nitsdangerous==2.1.2\\njedi==0.18.1\\njeepney==0.8.0\\nJinja2==2.11.2\\njmespath @ file:///Users/ktietz/demo/mc3/conda-bld/jmespath_1630583964805/work\\njoblib==0.14.1\\njson-logging-py==0.2\\njsonpickle==2.2.0\\njsonschema==4.16.0\\njupyter-client==7.4.4\\njupyter-core==4.11.2\\nkeras2onnx==1.6.0\\nkiwisolver @ file:///opt/conda/conda-bld/kiwisolver_1653292039266/work\\nknack==0.10.0\\nkorean-lunar-calendar @ file:///tmp/build/80754af9/korean_lunar_calendar_1634063020401/work\\nlightgbm==3.2.1\\nllvmlite==0.38.1\\nlocket==1.0.0\\nLunarCalendar @ file:///tmp/build/80754af9/lunarcalendar_1646383991234/work\\nMarkupSafe==2.0.1\\nmatplotlib @ file:///tmp/build/80754af9/matplotlib-suite_1647441664166/work\\nmatplotlib-inline==0.1.6\\nml-wrappers==0.2.2\\nmlflow-skinny==1.30.0\\nmpi4py @ file:///home/conda/feedstock_root/build_artifacts/mpi4py_1660326262210/work\\nmpmath==1.2.1\\nmsal==1.20.0\\nmsal-extensions==1.0.0\\nmsgpack==1.0.4\\nmsrest==0.7.1\\nmsrestazure==0.6.4\\nmunkres==1.1.4\\nndg-httpsclient==0.5.1\\nnest-asyncio==1.5.6\\nnetCDF4==1.5.7\\nnetworkx==2.5\\nnimbusml==1.8.0\\nnumba==0.55.2\\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1649806299270/work\\noauthlib==3.2.2\\nonnx==1.12.0\\nonnxconverter-common==1.6.0\\nonnxmltools==1.4.1\\nonnxruntime==1.11.1\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.7\\npackaging @ file:///tmp/build/80754af9/packaging_1637314298585/work\\npandas==1.1.5\\nparamiko==2.11.0\\nparso==0.8.3\\npartd==1.3.0\\npathspec==0.10.1\\npatsy==0.5.3\\npexpect==4.8.0\\npickleshare==0.7.5\\nPillow==9.2.0\\npkginfo==1.8.3\\npkgutil-resolve-name==1.3.10\\npmdarima==1.7.1\\nportalocker==2.6.0\\nprompt-toolkit==3.0.31\\nprotobuf==3.20.1\\npsutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work\\nptyprocess==0.7.0\\npy-cpuinfo==5.0.0\\npyarrow==9.0.0\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\\npydot==1.4.2\\nPygments==2.13.0\\nPyJWT==2.6.0\\nPyMeeus @ file:///tmp/build/80754af9/pymeeus_1634069098549/work\\nPyNaCl==1.5.0\\npyOpenSSL @ file:///opt/conda/conda-bld/pyopenssl_1643788558760/work\\npyparsing @ file:///tmp/build/80754af9/pyparsing_1635766073266/work\\npyrsistent==0.19.1\\nPySocks @ file:///tmp/build/80754af9/pysocks_1594394576006/work\\npystan @ file:///tmp/build/80754af9/pystan_1613565226242/work\\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\\npytz @ file:///opt/conda/conda-bld/pytz_1654762638606/work\\nPyYAML==6.0\\npyzmq==24.0.1\\nraiutils==0.2.0\\nrequests==2.28.1\\nrequests-oauthlib==1.3.1\\nresponsibleai==0.22.0\\nrsa==4.9\\ns3transfer @ file:///tmp/build/80754af9/s3transfer_1616183147336/work\\nscikit-learn==0.22.1\\nscipy==1.5.3\\nSecretStorage==3.3.3\\nsemver==2.13.0\\nsetuptools-git==1.2\\nshap==0.39.0\\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\\nskl2onnx==1.4.9\\nsklearn-pandas==1.7.0\\nslicer==0.0.7\\nsmart-open==1.9.0\\nsmmap==5.0.0\\nsortedcontainers==2.4.0\\nsparse==0.13.0\\nsqlparse==0.4.3\\nstatsmodels==0.11.1\\nsympy==1.10.1\\ntabulate==0.9.0\\ntblib==1.7.0\\ntermcolor==2.1.0\\ntoolz==0.12.0\\ntornado==6.2\\ntqdm @ file:///opt/conda/conda-bld/tqdm_1650891076910/work\\ntraitlets==5.5.0\\ntyping-extensions @ file:///tmp/abs_ben9emwtky/croots/recipe/typing_extensions_1659638822008/work\\nurllib3 @ file:///tmp/build/80754af9/urllib3_1603305693037/work\\nwcwidth==0.2.5\\nwebsocket-client==1.4.1\\nWerkzeug==2.2.2\\nwrapt==1.12.1\\nxarray @ file:///opt/conda/conda-bld/xarray_1639166117697/work\\nxgboost==1.3.3\\nzict==2.2.0\\nzipp==3.10.0\\n\\n2022-11-06T07:13:02,503110700+00:00 | gunicorn/run | \\n2022-11-06T07:13:02,509003200+00:00 | gunicorn/run | ###############################################\\n2022-11-06T07:13:02,510554900+00:00 | gunicorn/run | AzureML Inference Server\\n2022-11-06T07:13:02,512076100+00:00 | gunicorn/run | ###############################################\\n2022-11-06T07:13:02,513580000+00:00 | gunicorn/run | \\n2022-11-06T07:13:05,245865115+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.7.6\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: /var/azureml-app/main.py\\nModel Directory: /var/azureml-app/azureml-models/spotify-popularity-model/2\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: None\\nInferencing HTTP server version: azmlinfsrv/0.7.6\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (74)\\nUsing worker: sync\\nBooting worker with pid: 128\\nInitializing logger\\n2022-11-06 07:13:06,554 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-11-06 07:13:06,555 | root | INFO | Starting up app insight hooks\\n2022-11-06 07:13:09,135 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\n2022-11-06 07:13:09,147 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\n2022-11-06 07:13:09,163 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\n2022-11-06 07:13:09,173 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\n2022-11-06 07:13:09,285 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-identity 1.11.0 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'azure-identity==1.7.0\\'), {\\'azureml-dataprep\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-identity 1.11.0 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'azure-identity==1.7.0\\'), {\\'azureml-dataprep\\'}).\\n2022-11-06 07:13:09,300 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.25.11 (/azureml-envs/azureml_bd40b1c03779eb152f0fb9bbd7fd1c81/lib/python3.7/site-packages), Requirement.parse(\\'urllib3>=1.26.0\\'), {\\'docker\\'}).\\n2022-11-06 07:13:09,314 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /var/azureml-app/score.py\\n2022-11-06 07:13:09,314 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\\n2022-11-06 07:13:09,314 | root | INFO | Invoking user\\'s init function\\ngenerated new fontManager\\nImporting plotly failed. Interactive plots will not work.\\n2022-11-06 07:13:18,992 | root | INFO | Users\\'s init has completed successfully\\n2022-11-06 07:13:18,994 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\n2022-11-06 07:13:18,995 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\\n2022-11-06 07:13:18,995 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n2022-11-06 07:13:38,073 | root | INFO | 200\\n127.0.0.1 - - [06/Nov/2022:07:13:38 +0000] \"GET /swagger.json HTTP/1.0\" 200 2263 \"-\" \"Go-http-client/1.1\"\\n2022-11-06 07:13:43,492 | root | INFO | 200\\n127.0.0.1 - - [06/Nov/2022:07:13:43 +0000] \"GET /swagger.json HTTP/1.0\" 200 2263 \"-\" \"Go-http-client/1.1\"\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 129,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667718924866
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()\n",
        "compute_target.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current provisioning state of AmlCompute is \"Deleting\"\n\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\n"
        }
      ],
      "execution_count": 140,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667719469222
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}